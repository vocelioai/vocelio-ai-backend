"""
AI Brain Generation Endpoints
Advanced AI text generation and conversation optimization
"""

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from typing import List, Optional, Dict, Any
import asyncio
from datetime import datetime

from src.services.ai_service import AIService
from src.schemas.generation import (
    ConversationRequest,
    ConversationResponse,
    OptimizationRequest,
    OptimizationResponse,
    GenerationMetrics,
    ConversationContext,
    ResponseOptimization
)
from shared.auth.dependencies import get_current_user
from shared.models.user import User

router = APIRouter()

@router.post("/conversation", response_model=ConversationResponse)
async def generate_conversation(
    request: ConversationRequest,
    background_tasks: BackgroundTasks,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    ü§ñ Generate AI conversation response with real-time optimization
    
    Advanced AI generation with:
    - Real-time context analysis
    - Sentiment-aware responses
    - Industry-specific optimization
    - Performance tracking
    """
    try:
        # Generate AI response with context
        response = await ai_service.generate_conversation_response(
            message=request.message,
            context=request.context,
            agent_id=request.agent_id,
            optimization_level=request.optimization_level,
            user_id=current_user.id
        )
        
        # Background tasks for optimization
        background_tasks.add_task(
            ai_service.log_conversation_metrics,
            request.agent_id,
            request.message,
            response.generated_text,
            response.confidence_score
        )
        
        background_tasks.add_task(
            ai_service.update_learning_model,
            request.context,
            response
        )
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI generation failed: {str(e)}")

@router.post("/optimize-response", response_model=OptimizationResponse)
async def optimize_conversation_response(
    request: OptimizationRequest,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    ‚ö° Real-time conversation response optimization
    
    Features:
    - A/B testing for response variations
    - Performance-based optimization
    - Industry-specific tuning
    - Success rate prediction
    """
    try:
        optimization = await ai_service.optimize_conversation_response(
            original_response=request.original_response,
            context=request.context,
            target_metrics=request.target_metrics,
            optimization_goals=request.optimization_goals
        )
        
        return optimization
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Optimization failed: {str(e)}")

@router.get("/conversation/context/{agent_id}", response_model=ConversationContext)
async def get_conversation_context(
    agent_id: str,
    limit: int = 10,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    üìù Retrieve conversation context for AI agent
    
    Returns:
    - Recent conversation history
    - Performance metrics
    - Optimization suggestions
    - Context analysis
    """
    try:
        context = await ai_service.get_conversation_context(
            agent_id=agent_id,
            limit=limit,
            user_id=current_user.id
        )
        
        return context
        
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"Context not found: {str(e)}")

@router.post("/conversation/feedback")
async def submit_conversation_feedback(
    agent_id: str,
    conversation_id: str,
    feedback_score: float,
    feedback_text: Optional[str] = None,
    background_tasks: BackgroundTasks,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    üìù Submit feedback for AI conversation
    
    Enables continuous learning through:
    - Human feedback integration
    - Performance scoring
    - Model improvement
    - Quality assurance
    """
    try:
        # Process feedback
        await ai_service.process_conversation_feedback(
            agent_id=agent_id,
            conversation_id=conversation_id,
            feedback_score=feedback_score,
            feedback_text=feedback_text,
            user_id=current_user.id
        )
        
        # Background learning update
        background_tasks.add_task(
            ai_service.update_model_from_feedback,
            agent_id,
            feedback_score,
            feedback_text
        )
        
        return {
            "status": "success",
            "message": "Feedback processed successfully",
            "learning_update": "Model optimization queued"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Feedback processing failed: {str(e)}")

@router.get("/generation/metrics", response_model=GenerationMetrics)
async def get_generation_metrics(
    agent_id: Optional[str] = None,
    time_range: str = "24h",
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    üìä Get AI generation performance metrics
    
    Metrics include:
    - Generation accuracy
    - Response time
    - Success rates
    - Optimization impact
    """
    try:
        metrics = await ai_service.get_generation_metrics(
            agent_id=agent_id,
            time_range=time_range,
            user_id=current_user.id
        )
        
        return metrics
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Metrics retrieval failed: {str(e)}")

@router.post("/conversation/batch-optimize")
async def batch_optimize_conversations(
    agent_ids: List[str],
    optimization_goals: Dict[str, Any],
    background_tasks: BackgroundTasks,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    üöÄ Batch optimize multiple AI agents
    
    Enterprise feature for:
    - Bulk optimization
    - Performance improvement
    - Cost reduction
    - Scale operations
    """
    try:
        # Start batch optimization
        task_id = await ai_service.start_batch_optimization(
            agent_ids=agent_ids,
            optimization_goals=optimization_goals,
            user_id=current_user.id
        )
        
        # Background processing
        background_tasks.add_task(
            ai_service.process_batch_optimization,
            task_id,
            agent_ids,
            optimization_goals
        )
        
        return {
            "status": "started",
            "task_id": task_id,
            "message": f"Batch optimization started for {len(agent_ids)} agents",
            "estimated_completion": "15-30 minutes",
            "agents_count": len(agent_ids)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch optimization failed: {str(e)}")

@router.get("/conversation/optimization-status/{task_id}")
async def get_optimization_status(
    task_id: str,
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    üìà Get batch optimization status
    """
    try:
        status = await ai_service.get_optimization_status(task_id)
        return status
        
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"Task not found: {str(e)}")

@router.post("/conversation/real-time-optimization")
async def enable_real_time_optimization(
    agent_id: str,
    optimization_settings: Dict[str, Any],
    ai_service: AIService = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    ‚ö° Enable real-time AI optimization for agent
    """
    try:
        result = await ai_service.enable_real_time_optimization(
            agent_id=agent_id,
            settings=optimization_settings,
            user_id=current_user.id
        )
        
        return {
            "status": "enabled",
            "agent_id": agent_id,
            "optimization_active": True,
            "settings": optimization_settings,
            "expected_improvement": result.get("expected_improvement", "15-25%")
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Real-time optimization failed: {str(e)}")
